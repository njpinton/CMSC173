{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods Workshop\n",
    "\n",
    "**CMSC 173 - Machine Learning**  \n",
    "**University of the Philippines - Cebu**  \n",
    "**Instructor:** Noel Jeffrey Pinton  \n",
    "**Department:** Department of Computer Science\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By the end of this workshop, you will be able to:\n",
    "\n",
    "1. **Understand** the fundamental concepts of classification and supervised learning\n",
    "2. **Implement** Naive Bayes, K-Nearest Neighbors, and Decision Trees from scratch\n",
    "3. **Apply** classification algorithms to real-world datasets\n",
    "4. **Evaluate** classification performance using appropriate metrics\n",
    "5. **Compare** different classification methods and choose the best for a given problem\n",
    "\n",
    "**Estimated Time:** 75-90 minutes  \n",
    "**Prerequisites:** Linear algebra, Python, NumPy, basic probability\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Table of Contents\n",
    "\n",
    "1. [Setup & Imports](#setup)\n",
    "2. [Part 1: Motivation & Background](#part1)\n",
    "3. [Part 2: Naive Bayes Classification](#part2)\n",
    "4. [Part 3: K-Nearest Neighbors](#part3)\n",
    "5. [Part 4: Decision Trees](#part4)\n",
    "6. [Part 5: Comparison & Evaluation](#part5)\n",
    "7. [Part 6: Advanced Topics](#part6)\n",
    "8. [Student Challenge](#challenge)\n",
    "9. [Solutions](#solutions)\n",
    "10. [Summary & Next Steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ… Environment setup complete!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Python packages loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part1'></a>\n",
    "## 2. Part 1: Motivation & Background\n",
    "\n",
    "### What is Classification?\n",
    "\n",
    "**Classification** is a supervised learning task where we predict a discrete class label for new observations based on training examples.\n",
    "\n",
    "**Key Characteristics:**\n",
    "- Supervised learning (requires labeled training data)\n",
    "- Discrete output (categories/classes)\n",
    "- Learn from examples\n",
    "- Make predictions on new data\n",
    "\n",
    "**Real-World Applications:**\n",
    "- Medical diagnosis (disease detection)\n",
    "- Email spam filtering\n",
    "- Credit scoring (loan approval)\n",
    "- Image recognition (object classification)\n",
    "- Sentiment analysis (positive/negative reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classic Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "print(\"Iris Dataset Overview\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Number of samples: {X_iris.shape[0]}\")\n",
    "print(f\"Number of features: {X_iris.shape[1]}\")\n",
    "print(f\"Number of classes: {len(target_names)}\")\n",
    "print(f\"\\nFeatures: {feature_names}\")\n",
    "print(f\"Classes: {list(target_names)}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "for i, name in enumerate(target_names):\n",
    "    count = np.sum(y_iris == i)\n",
    "    print(f\"  {name}: {count} samples\")\n",
    "\n",
    "# Visualize the data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot of first two features\n",
    "for i, name in enumerate(target_names):\n",
    "    mask = y_iris == i\n",
    "    axes[0].scatter(X_iris[mask, 0], X_iris[mask, 1], \n",
    "                   s=80, alpha=0.6, edgecolors='k', label=name)\n",
    "axes[0].set_xlabel(feature_names[0])\n",
    "axes[0].set_ylabel(feature_names[1])\n",
    "axes[0].set_title('Iris Dataset: 2D Visualization', fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot of all features\n",
    "df = pd.DataFrame(X_iris, columns=feature_names)\n",
    "df['species'] = [target_names[i] for i in y_iris]\n",
    "df_melt = pd.melt(df, id_vars='species', var_name='feature', value_name='value')\n",
    "sns.boxplot(data=df_melt, x='feature', y='value', hue='species', ax=axes[1])\n",
    "axes[1].set_title('Feature Distributions by Class', fontweight='bold')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2'></a>\n",
    "## 3. Part 2: Naive Bayes Classification\n",
    "\n",
    "### Theory: Bayes' Theorem\n",
    "\n",
    "$$P(C_k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | C_k) \\cdot P(C_k)}{P(\\mathbf{x})}$$\n",
    "\n",
    "**Naive Assumption:** Features are conditionally independent given the class\n",
    "\n",
    "$$P(\\mathbf{x} | C_k) = \\prod_{i=1}^{d} P(x_i | C_k)$$\n",
    "\n",
    "**Classification Rule:**\n",
    "\n",
    "$$\\hat{y} = \\arg\\max_{k} P(C_k) \\prod_{i=1}^{d} P(x_i | C_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Gaussian Naive Bayes from scratch\n",
    "class GaussianNBFromScratch:\n",
    "    \"\"\"Gaussian Naive Bayes classifier for educational purposes\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.priors = {}\n",
    "        self.means = {}\n",
    "        self.vars = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit Gaussian Naive Bayes\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        self.classes = np.unique(y)\n",
    "        \n",
    "        # Compute parameters for each class\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            \n",
    "            # Prior probability\n",
    "            self.priors[c] = len(X_c) / n_samples\n",
    "            \n",
    "            # Mean and variance for each feature\n",
    "            self.means[c] = X_c.mean(axis=0)\n",
    "            self.vars[c] = X_c.var(axis=0)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _gaussian_pdf(self, x, mean, var):\n",
    "        \"\"\"Compute Gaussian probability density function\"\"\"\n",
    "        eps = 1e-9  # Small value to avoid division by zero\n",
    "        coeff = 1.0 / np.sqrt(2 * np.pi * var + eps)\n",
    "        exponent = np.exp(-((x - mean) ** 2) / (2 * var + eps))\n",
    "        return coeff * exponent\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities for X\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        n_classes = len(self.classes)\n",
    "        probs = np.zeros((n_samples, n_classes))\n",
    "        \n",
    "        for idx, c in enumerate(self.classes):\n",
    "            # Compute log probabilities to avoid underflow\n",
    "            log_prior = np.log(self.priors[c])\n",
    "            log_likelihood = np.sum(\n",
    "                np.log(self._gaussian_pdf(X, self.means[c], self.vars[c]) + 1e-9),\n",
    "                axis=1\n",
    "            )\n",
    "            probs[:, idx] = log_prior + log_likelihood\n",
    "        \n",
    "        # Convert back from log space and normalize\n",
    "        probs = np.exp(probs)\n",
    "        probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels for X\"\"\"\n",
    "        probs = self.predict_proba(X)\n",
    "        return self.classes[np.argmax(probs, axis=1)]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.3, random_state=42, stratify=y_iris\n",
    ")\n",
    "\n",
    "# Train from scratch\n",
    "nb_scratch = GaussianNBFromScratch()\n",
    "nb_scratch.fit(X_train, y_train)\n",
    "\n",
    "# Train sklearn version\n",
    "nb_sklearn = GaussianNB()\n",
    "nb_sklearn.fit(X_train, y_train)\n",
    "\n",
    "# Compare predictions\n",
    "y_pred_scratch = nb_scratch.predict(X_test)\n",
    "y_pred_sklearn = nb_sklearn.predict(X_test)\n",
    "\n",
    "print(\"Gaussian Naive Bayes Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"From Scratch - Train Accuracy: {accuracy_score(y_train, nb_scratch.predict(X_train)):.3f}\")\n",
    "print(f\"From Scratch - Test Accuracy:  {accuracy_score(y_test, y_pred_scratch):.3f}\")\n",
    "print(f\"\\nSklearn     - Train Accuracy: {accuracy_score(y_train, nb_sklearn.predict(X_train)):.3f}\")\n",
    "print(f\"Sklearn     - Test Accuracy:  {accuracy_score(y_test, y_pred_sklearn):.3f}\")\n",
    "print(f\"\\nPredictions match: {np.allclose(y_pred_scratch, y_pred_sklearn)}\")\n",
    "\n",
    "# Display learned parameters\n",
    "print(\"\\nLearned Parameters (From Scratch):\")\n",
    "print(\"-\" * 50)\n",
    "for c in nb_scratch.classes:\n",
    "    print(f\"\\nClass {target_names[c]}:\")\n",
    "    print(f\"  Prior: {nb_scratch.priors[c]:.3f}\")\n",
    "    print(f\"  Means: {nb_scratch.means[c]}\")\n",
    "    print(f\"  Variances: {nb_scratch.vars[c]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Naive Bayes decision boundaries (2D projection)\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundaries(X, y, classifier, title, feature_indices=(0, 1)):\n",
    "    \"\"\"Plot decision boundaries for 2D data\"\"\"\n",
    "    # Use only two features\n",
    "    X_2d = X[:, feature_indices]\n",
    "    \n",
    "    # Train classifier on 2D data\n",
    "    classifier.fit(X_2d, y)\n",
    "    \n",
    "    # Create mesh\n",
    "    h = 0.02  # Step size\n",
    "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Predict on mesh\n",
    "    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "    cmap_bold = ['#FF0000', '#00FF00', '#0000FF']\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)\n",
    "    \n",
    "    # Plot training points\n",
    "    for i, name in enumerate(target_names):\n",
    "        mask = y == i\n",
    "        plt.scatter(X_2d[mask, 0], X_2d[mask, 1], \n",
    "                   c=cmap_bold[i], s=80, alpha=0.7, \n",
    "                   edgecolors='k', label=name)\n",
    "    \n",
    "    plt.xlabel(feature_names[feature_indices[0]])\n",
    "    plt.ylabel(feature_names[feature_indices[1]])\n",
    "    plt.title(title, fontweight='bold', fontsize=13)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot Naive Bayes boundaries\n",
    "plot_decision_boundaries(X_train, y_train, GaussianNB(), \n",
    "                        'Naive Bayes Decision Boundaries', (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part3'></a>\n",
    "## 4. Part 3: K-Nearest Neighbors\n",
    "\n",
    "### Theory: The KNN Algorithm\n",
    "\n",
    "**Core Idea:** \"You are the average of your $k$ closest neighbors\"\n",
    "\n",
    "**Algorithm:**\n",
    "1. Choose number of neighbors $k$\n",
    "2. For a new point:\n",
    "   - Compute distance to all training points\n",
    "   - Find $k$ nearest neighbors\n",
    "   - Take majority vote of their labels\n",
    "   - Return predicted class\n",
    "\n",
    "**Key Parameters:**\n",
    "- $k$: Number of neighbors (odd for binary classification)\n",
    "- Distance metric: Euclidean, Manhattan, Minkowski, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement KNN from scratch\n",
    "class KNNFromScratch:\n",
    "    \"\"\"K-Nearest Neighbors classifier for educational purposes\"\"\"\n",
    "    \n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Store training data (lazy learning)\"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        return self\n",
    "    \n",
    "    def _euclidean_distance(self, x1, x2):\n",
    "        \"\"\"Compute Euclidean distance\"\"\"\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2, axis=1))\n",
    "    \n",
    "    def _manhattan_distance(self, x1, x2):\n",
    "        \"\"\"Compute Manhattan distance\"\"\"\n",
    "        return np.sum(np.abs(x1 - x2), axis=1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels for X\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for x in X:\n",
    "            # Compute distances to all training points\n",
    "            if self.distance_metric == 'euclidean':\n",
    "                distances = self._euclidean_distance(self.X_train, x)\n",
    "            elif self.distance_metric == 'manhattan':\n",
    "                distances = self._manhattan_distance(self.X_train, x)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown distance metric: {self.distance_metric}\")\n",
    "            \n",
    "            # Find k nearest neighbors\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = self.y_train[k_indices]\n",
    "            \n",
    "            # Majority vote\n",
    "            most_common = np.bincount(k_nearest_labels).argmax()\n",
    "            predictions.append(most_common)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "# Must scale features for KNN!\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train from scratch with different k values\n",
    "print(\"KNN Performance for Different k Values\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for k in [1, 3, 5, 7, 9]:\n",
    "    knn_scratch = KNNFromScratch(k=k)\n",
    "    knn_scratch.fit(X_train_scaled, y_train)\n",
    "    y_pred = knn_scratch.predict(X_test_scaled)\n",
    "    \n",
    "    train_pred = knn_scratch.predict(X_train_scaled)\n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"k={k}: Train Acc={train_acc:.3f}, Test Acc={test_acc:.3f}\")\n",
    "\n",
    "# Compare with sklearn\n",
    "print(\"\\nComparison with Sklearn (k=5):\")\n",
    "print(\"-\" * 50)\n",
    "knn_sklearn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_sklearn.fit(X_train_scaled, y_train)\n",
    "print(f\"Sklearn - Train Accuracy: {knn_sklearn.score(X_train_scaled, y_train):.3f}\")\n",
    "print(f\"Sklearn - Test Accuracy:  {knn_sklearn.score(X_test_scaled, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of k on decision boundaries\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for idx, k in enumerate([1, 5, 15]):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Use only two features for visualization\n",
    "    X_2d = X_train_scaled[:, [0, 1]]\n",
    "    knn.fit(X_2d, y_train)\n",
    "    \n",
    "    # Create mesh\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "    cmap_bold = ['#FF0000', '#00FF00', '#0000FF']\n",
    "    \n",
    "    axes[idx].contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)\n",
    "    \n",
    "    for i, name in enumerate(target_names):\n",
    "        mask = y_train == i\n",
    "        axes[idx].scatter(X_2d[mask, 0], X_2d[mask, 1],\n",
    "                         c=cmap_bold[i], s=60, alpha=0.7,\n",
    "                         edgecolors='k', label=name)\n",
    "    \n",
    "    axes[idx].set_xlabel(f'Feature 1 (scaled)')\n",
    "    axes[idx].set_ylabel(f'Feature 2 (scaled)')\n",
    "    axes[idx].set_title(f'KNN with k={k}', fontweight='bold')\n",
    "    if idx == 0:\n",
    "        axes[idx].legend()\n",
    "\n",
    "plt.suptitle('Effect of k on Decision Boundaries', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal k using cross-validation\n",
    "k_values = range(1, 31)\n",
    "cv_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "optimal_k = k_values[np.argmax(cv_scores)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, cv_scores, marker='o', linewidth=2)\n",
    "plt.axvline(x=optimal_k, color='r', linestyle='--', label=f'Optimal k = {optimal_k}')\n",
    "plt.xlabel('Number of Neighbors (k)', fontweight='bold')\n",
    "plt.ylabel('Cross-Validation Accuracy', fontweight='bold')\n",
    "plt.title('Finding Optimal k using Cross-Validation', fontweight='bold', fontsize=13)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Optimal k: {optimal_k}\")\n",
    "print(f\"Best CV accuracy: {max(cv_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part4'></a>\n",
    "## 5. Part 4: Decision Trees\n",
    "\n",
    "### Theory: Decision Tree Learning\n",
    "\n",
    "**Goal:** Build a tree of if-then-else rules to classify data\n",
    "\n",
    "**CART Algorithm (Classification And Regression Trees):**\n",
    "1. Start with all data at root\n",
    "2. Find best split that maximizes information gain\n",
    "3. Partition data into left and right subsets\n",
    "4. Recursively build subtrees\n",
    "5. Stop when stopping criterion met\n",
    "\n",
    "**Splitting Criteria:**\n",
    "\n",
    "**Gini Impurity:**\n",
    "$$\\text{Gini}(D) = 1 - \\sum_{k=1}^{C} p_k^2$$\n",
    "\n",
    "**Entropy (Information Gain):**\n",
    "$$\\text{Entropy}(D) = -\\sum_{k=1}^{C} p_k \\log_2(p_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree with different depths\n",
    "print(\"Decision Tree Performance for Different Depths\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for depth in [2, 3, 5, 10, None]:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = dt.score(X_train, y_train)\n",
    "    test_acc = dt.score(X_test, y_test)\n",
    "    \n",
    "    depth_str = str(depth) if depth is not None else 'None'\n",
    "    print(f\"max_depth={depth_str:>4}: Train Acc={train_acc:.3f}, Test Acc={test_acc:.3f}\")\n",
    "\n",
    "# Train final model with optimal depth\n",
    "dt_final = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dt_final.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nFinal Model (max_depth=3):\")\n",
    "print(f\"  Number of leaves: {dt_final.get_n_leaves()}\")\n",
    "print(f\"  Tree depth: {dt_final.get_depth()}\")\n",
    "print(f\"  Number of features used: {np.sum(dt_final.feature_importances_ > 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt_final, \n",
    "          feature_names=feature_names,\n",
    "          class_names=target_names,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Visualization (max_depth=3)', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = dt_final.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(importances)), importances[indices], color='steelblue', edgecolor='black')\n",
    "plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "plt.xlabel('Features', fontweight='bold')\n",
    "plt.ylabel('Importance', fontweight='bold')\n",
    "plt.title('Feature Importance in Decision Tree', fontweight='bold', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature Importance Ranking:\")\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"{i+1}. {feature_names[idx]}: {importances[idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decision boundaries for decision tree\n",
    "plot_decision_boundaries(X_train, y_train, \n",
    "                        DecisionTreeClassifier(max_depth=3, random_state=42),\n",
    "                        'Decision Tree Decision Boundaries (max_depth=3)', (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part5'></a>\n",
    "## 6. Part 5: Comparison & Evaluation\n",
    "\n",
    "### Performance Metrics\n",
    "\n",
    "For classification, we use multiple metrics:\n",
    "\n",
    "1. **Accuracy:** Proportion of correct predictions\n",
    "2. **Precision:** TP / (TP + FP) - Of predicted positives, how many are correct?\n",
    "3. **Recall:** TP / (TP + FN) - Of actual positives, how many did we find?\n",
    "4. **F1-Score:** Harmonic mean of precision and recall\n",
    "5. **Confusion Matrix:** Visual breakdown of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all three classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'KNN (k=5)': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree (depth=3)': DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    # Use scaled data for KNN, original for others\n",
    "    if 'KNN' in name:\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "        train_acc = clf.score(X_train_scaled, y_train)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        train_acc = clf.score(X_train, y_train)\n",
    "    \n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    results.append({\n",
    "        'Method': name,\n",
    "        'Train Acc': train_acc,\n",
    "        'Test Acc': test_acc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nPerformance Comparison on Iris Dataset\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot of test accuracies\n",
    "axes[0].bar(results_df['Method'], results_df['Test Acc'], color='steelblue', edgecolor='black')\n",
    "axes[0].set_ylabel('Test Accuracy', fontweight='bold')\n",
    "axes[0].set_title('Test Accuracy Comparison', fontweight='bold')\n",
    "axes[0].set_ylim([0.85, 1.0])\n",
    "axes[0].set_xticklabels(results_df['Method'], rotation=15, ha='right')\n",
    "\n",
    "# Grouped bar plot of all metrics\n",
    "metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.25\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    axes[1].bar(x + i * width, results_df[metric], width, label=metric, edgecolor='black')\n",
    "\n",
    "axes[1].set_ylabel('Score', fontweight='bold')\n",
    "axes[1].set_title('Performance Metrics Comparison', fontweight='bold')\n",
    "axes[1].set_xticks(x + width)\n",
    "axes[1].set_xticklabels(results_df['Method'], rotation=15, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].set_ylim([0.85, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for idx, (name, clf) in enumerate(classifiers.items()):\n",
    "    # Get predictions\n",
    "    if 'KNN' in name:\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "    else:\n",
    "        y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Plot\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=target_names, yticklabels=target_names,\n",
    "                ax=axes[idx], cbar=True)\n",
    "    axes[idx].set_xlabel('Predicted', fontweight='bold')\n",
    "    axes[idx].set_ylabel('Actual', fontweight='bold')\n",
    "    axes[idx].set_title(f'{name}', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Confusion Matrices', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part6'></a>\n",
    "## 7. Part 6: Advanced Topics\n",
    "\n",
    "### Text Classification with Naive Bayes\n",
    "\n",
    "Naive Bayes is particularly effective for text classification tasks like spam detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple text classification example\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Sample email dataset (spam/ham)\n",
    "emails = [\n",
    "    \"Free money now!!!\",\n",
    "    \"Hi Bob, how was your weekend?\",\n",
    "    \"Win a lottery jackpot!\",\n",
    "    \"Meeting at 3pm tomorrow\",\n",
    "    \"Claim your prize immediately\",\n",
    "    \"Lunch next week?\",\n",
    "    \"URGENT: Act now for free prize\",\n",
    "    \"Can you send the report?\"\n",
    "]\n",
    "\n",
    "labels = [1, 0, 1, 0, 1, 0, 1, 0]  # 1 = spam, 0 = ham\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = CountVectorizer()\n",
    "X_text = vectorizer.fit_transform(emails)\n",
    "\n",
    "# Train Multinomial Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_text, labels)\n",
    "\n",
    "# Test predictions\n",
    "test_emails = [\n",
    "    \"Free prize waiting for you\",\n",
    "    \"See you at the meeting\"\n",
    "]\n",
    "\n",
    "X_test_text = vectorizer.transform(test_emails)\n",
    "predictions = mnb.predict(X_test_text)\n",
    "probabilities = mnb.predict_proba(X_test_text)\n",
    "\n",
    "print(\"Text Classification Demo (Spam Detection)\")\n",
    "print(\"=\" * 50)\n",
    "for email, pred, prob in zip(test_emails, predictions, probabilities):\n",
    "    label = \"SPAM\" if pred == 1 else \"HAM\"\n",
    "    confidence = prob[pred]\n",
    "    print(f\"\\nEmail: \\\"{email}\\\"\")\n",
    "    print(f\"Prediction: {label} (confidence: {confidence:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods Preview: Random Forest\n",
    "\n",
    "Random Forest combines multiple decision trees to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Compare single tree vs Random Forest\n",
    "dt_single = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "\n",
    "dt_single.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Single Decision Tree vs Random Forest\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Decision Tree - Test Accuracy: {dt_single.score(X_test, y_test):.3f}\")\n",
    "print(f\"Random Forest  - Test Accuracy: {rf.score(X_test, y_test):.3f}\")\n",
    "print(f\"\\nImprovement: {(rf.score(X_test, y_test) - dt_single.score(X_test, y_test)):.3f}\")\n",
    "\n",
    "print(\"\\nNote: Random Forest typically provides more robust predictions\")\n",
    "print(\"by averaging multiple trees. This will be covered in detail in\")\n",
    "print(\"the Ensemble Methods module!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='challenge'></a>\n",
    "## 8. Student Challenge\n",
    "\n",
    "### Challenge Tasks\n",
    "\n",
    "Apply what you've learned to the **Wine dataset**. Complete the following tasks:\n",
    "\n",
    "1. **Load and explore** the Wine dataset\n",
    "2. **Split** the data into train/test sets (70/30 split)\n",
    "3. **Train** all three classifiers (Naive Bayes, KNN, Decision Tree)\n",
    "4. **Tune** hyperparameters using cross-validation:\n",
    "   - Find optimal k for KNN\n",
    "   - Find optimal max_depth for Decision Tree\n",
    "5. **Compare** performance using accuracy, precision, recall, F1-score\n",
    "6. **Visualize** confusion matrices for all three methods\n",
    "7. **Interpret** which method works best and why\n",
    "\n",
    "**Bonus Challenge:**\n",
    "- Try the Breast Cancer dataset instead\n",
    "- Experiment with feature selection\n",
    "- Create ROC curves for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Load and explore Wine dataset\n",
    "wine = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "\n",
    "# YOUR CODE HERE\n",
    "print(\"Wine Dataset Overview:\")\n",
    "print(f\"Number of samples: {X_wine.shape[0]}\")\n",
    "print(f\"Number of features: {X_wine.shape[1]}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_wine))}\")\n",
    "print(f\"\\nFeature names: {wine.feature_names[:5]}...\")  # Show first 5\n",
    "print(f\"Target names: {list(wine.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2-7: YOUR CODE HERE\n",
    "# Split data, train classifiers, tune parameters, compare performance\n",
    "\n",
    "# Hint for Task 2: Use train_test_split with test_size=0.3\n",
    "# Hint for Task 3: Don't forget to scale data for KNN!\n",
    "# Hint for Task 4: Use GridSearchCV or loop over parameter values\n",
    "# Hint for Task 5: Use the metrics functions from sklearn.metrics\n",
    "# Hint for Task 6: Use confusion_matrix and sns.heatmap\n",
    "\n",
    "pass  # Remove this and add your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='solutions'></a>\n",
    "## 9. Solutions\n",
    "\n",
    "### Challenge Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Student Challenge\n",
    "\n",
    "# Task 1: Already done above\n",
    "\n",
    "# Task 2: Split data\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
    "    X_wine, y_wine, test_size=0.3, random_state=42, stratify=y_wine\n",
    ")\n",
    "\n",
    "# Scale for KNN\n",
    "scaler_wine = StandardScaler()\n",
    "X_train_wine_scaled = scaler_wine.fit_transform(X_train_wine)\n",
    "X_test_wine_scaled = scaler_wine.transform(X_test_wine)\n",
    "\n",
    "# Task 3 & 4: Train and tune classifiers\n",
    "wine_classifiers = {}\n",
    "\n",
    "# Naive Bayes (no tuning needed)\n",
    "wine_classifiers['Naive Bayes'] = GaussianNB()\n",
    "wine_classifiers['Naive Bayes'].fit(X_train_wine, y_train_wine)\n",
    "\n",
    "# KNN with optimal k\n",
    "k_range = range(1, 21)\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn_temp = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn_temp, X_train_wine_scaled, y_train_wine, cv=5)\n",
    "    k_scores.append(scores.mean())\n",
    "\n",
    "optimal_k_wine = k_range[np.argmax(k_scores)]\n",
    "print(f\"Optimal k for Wine dataset: {optimal_k_wine}\")\n",
    "\n",
    "wine_classifiers['KNN'] = KNeighborsClassifier(n_neighbors=optimal_k_wine)\n",
    "wine_classifiers['KNN'].fit(X_train_wine_scaled, y_train_wine)\n",
    "\n",
    "# Decision Tree with optimal depth\n",
    "depth_range = [2, 3, 5, 7, 10, 15]\n",
    "depth_scores = []\n",
    "for depth in depth_range:\n",
    "    dt_temp = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    scores = cross_val_score(dt_temp, X_train_wine, y_train_wine, cv=5)\n",
    "    depth_scores.append(scores.mean())\n",
    "\n",
    "optimal_depth_wine = depth_range[np.argmax(depth_scores)]\n",
    "print(f\"Optimal depth for Wine dataset: {optimal_depth_wine}\")\n",
    "\n",
    "wine_classifiers['Decision Tree'] = DecisionTreeClassifier(\n",
    "    max_depth=optimal_depth_wine, random_state=42\n",
    ")\n",
    "wine_classifiers['Decision Tree'].fit(X_train_wine, y_train_wine)\n",
    "\n",
    "# Task 5: Compare performance\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Performance on Wine Dataset\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "wine_results = []\n",
    "for name, clf in wine_classifiers.items():\n",
    "    # Use appropriate data (scaled for KNN)\n",
    "    if name == 'KNN':\n",
    "        y_pred = clf.predict(X_test_wine_scaled)\n",
    "        train_acc = clf.score(X_train_wine_scaled, y_train_wine)\n",
    "    else:\n",
    "        y_pred = clf.predict(X_test_wine)\n",
    "        train_acc = clf.score(X_train_wine, y_train_wine)\n",
    "    \n",
    "    test_acc = accuracy_score(y_test_wine, y_pred)\n",
    "    precision = precision_score(y_test_wine, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test_wine, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test_wine, y_pred, average='weighted')\n",
    "    \n",
    "    wine_results.append({\n",
    "        'Method': name,\n",
    "        'Train Acc': train_acc,\n",
    "        'Test Acc': test_acc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "\n",
    "wine_results_df = pd.DataFrame(wine_results)\n",
    "print(wine_results_df.to_string(index=False))\n",
    "\n",
    "# Task 6: Confusion matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for idx, (name, clf) in enumerate(wine_classifiers.items()):\n",
    "    if name == 'KNN':\n",
    "        y_pred = clf.predict(X_test_wine_scaled)\n",
    "    else:\n",
    "        y_pred = clf.predict(X_test_wine)\n",
    "    \n",
    "    cm = confusion_matrix(y_test_wine, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=wine.target_names,\n",
    "                yticklabels=wine.target_names,\n",
    "                ax=axes[idx])\n",
    "    axes[idx].set_xlabel('Predicted', fontweight='bold')\n",
    "    axes[idx].set_ylabel('Actual', fontweight='bold')\n",
    "    axes[idx].set_title(f'{name}', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Confusion Matrices - Wine Dataset', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Task 7: Interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"-\" * 70)\n",
    "best_method = wine_results_df.loc[wine_results_df['Test Acc'].idxmax(), 'Method']\n",
    "best_acc = wine_results_df['Test Acc'].max()\n",
    "print(f\"Best performing method: {best_method}\")\n",
    "print(f\"Test accuracy: {best_acc:.3f}\")\n",
    "print(f\"\\nPossible reasons:\")\n",
    "print(\"- Wine features may have complex non-linear relationships\")\n",
    "print(\"- Feature scaling helps KNN perform better\")\n",
    "print(\"- Decision trees can capture feature interactions\")\n",
    "print(\"- Naive Bayes independence assumption may be too strong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "## 10. Summary & Next Steps\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "#### 1. Classification Methods\n",
    "- **Naive Bayes:** Fast probabilistic method, assumes independence\n",
    "- **K-Nearest Neighbors:** Instance-based, non-parametric, needs scaling\n",
    "- **Decision Trees:** Interpretable rules, handles mixed types, prone to overfit\n",
    "\n",
    "#### 2. Method Selection\n",
    "- Choose based on: data size, dimensionality, interpretability needs\n",
    "- Always try multiple methods and compare\n",
    "- Use cross-validation for hyperparameter tuning\n",
    "\n",
    "#### 3. Best Practices\n",
    "- Scale features for distance-based methods (KNN)\n",
    "- Use appropriate metrics (not just accuracy)\n",
    "- Visualize decision boundaries when possible\n",
    "- Check for overfitting (train vs test performance)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Practice:** Apply to different datasets (UCI ML Repository)\n",
    "2. **Read:** \n",
    "   - \"The Elements of Statistical Learning\" (Hastie et al.)\n",
    "   - \"Pattern Recognition and Machine Learning\" (Bishop)\n",
    "3. **Explore:**\n",
    "   - Support Vector Machines (SVM)\n",
    "   - Ensemble Methods (Random Forest, Boosting)\n",
    "   - Neural Networks\n",
    "4. **Build:** Create end-to-end ML pipeline with preprocessing, model selection, evaluation\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **Scikit-learn Documentation:** https://scikit-learn.org/stable/\n",
    "- **Kaggle Learn:** https://www.kaggle.com/learn\n",
    "- **UCI ML Repository:** https://archive.ics.uci.edu/ml/\n",
    "- **StatQuest Videos:** https://www.youtube.com/c/joshstarmer\n",
    "\n",
    "---\n",
    "\n",
    "### Workshop Complete! ðŸŽ‰\n",
    "\n",
    "You now have hands-on experience with three fundamental classification methods. Keep practicing and exploring!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Compare both datasets\n",
    "combined_results = pd.concat([\n",
    "    results_df.assign(Dataset='Iris'),\n",
    "    wine_results_df.assign(Dataset='Wine')\n",
    "])\n",
    "\n",
    "# Test accuracy comparison\n",
    "pivot_acc = combined_results.pivot(index='Method', columns='Dataset', values='Test Acc')\n",
    "pivot_acc.plot(kind='bar', ax=axes[0], color=['steelblue', 'orange'], edgecolor='black')\n",
    "axes[0].set_ylabel('Test Accuracy', fontweight='bold')\n",
    "axes[0].set_title('Test Accuracy: Iris vs Wine', fontweight='bold')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=15, ha='right')\n",
    "axes[0].legend(title='Dataset')\n",
    "axes[0].set_ylim([0.8, 1.0])\n",
    "\n",
    "# F1-score comparison\n",
    "pivot_f1 = combined_results.pivot(index='Method', columns='Dataset', values='F1-Score')\n",
    "pivot_f1.plot(kind='bar', ax=axes[1], color=['steelblue', 'orange'], edgecolor='black')\n",
    "axes[1].set_ylabel('F1-Score', fontweight='bold')\n",
    "axes[1].set_title('F1-Score: Iris vs Wine', fontweight='bold')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=15, ha='right')\n",
    "axes[1].legend(title='Dataset')\n",
    "axes[1].set_ylim([0.8, 1.0])\n",
    "\n",
    "plt.suptitle('Final Performance Comparison', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ Workshop Complete! Great job!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYou've successfully learned and implemented:\")\n",
    "print(\"  âœ“ Naive Bayes Classification\")\n",
    "print(\"  âœ“ K-Nearest Neighbors\")\n",
    "print(\"  âœ“ Decision Trees\")\n",
    "print(\"  âœ“ Performance Evaluation\")\n",
    "print(\"  âœ“ Model Comparison\")\n",
    "print(\"\\nKeep practicing and exploring! ðŸš€\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
